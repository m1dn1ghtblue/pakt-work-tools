Модуль построения оценок

В Модуле построения оценок реализованы два класса. Класс GrossModel
предназначен для работы с моделью определения грубости ошибки. Класс
MarkModel предназначен для работы с моделью для формирования оценки
текста.

Описание класса GrossModel
==========================

Class GrossModel(modelType = \'CosMeasure\', score = 0)

Параметры:

modelType -- тип модели; по умолчанию -- значение «CosMeasure»;
принимает одно из следующих значений:

-   CosMeasure -- загружается модель
    symanto/sn-xlm-roberta-base-snli-mnli-anli-xnli;

-   CrossEncoder -- загружается модель
    dbmdz/convbert-base-german-europeana-cased;

-   CrossEncoder2 -- загружается модель
    ml6team/cross-encoder-mmarco-german-distilbert-base;

-   BERTModel -- загружается модель severinsimmler/literary-german-bert;

-   distilBERTModel -- загружается модель distilbert-base-german-cased;

score -- границы для грубости ошибки; используется только с типами
моделей \'CosMeasure\', \'CrossEncoder\', \'CrossEncoder2\'; принимает
значение 0 (используются встроенные границы) или список из трех
убывающих значений, соответствующих уровням грубости 1, 2, 3; по
умолчанию -- значение 0.

Поля класса:

-   BERTmodel = \'severinsimmler/literary-german-bert\' -- название BERT
    модели искусственной нейронной сети;

-   Cosmodel = \'symanto/sn-xlm-roberta-base-snli-mnli-anli-xnli\' --
    название модели искусственной нейронной сети с использованием
    косинусной меры;

-   Crossmodel = \'dbmdz/convbert-base-german-europeana-cased\' --
    название модели искусственной нейронной сети на основе
    кросс-энкодера;

-   Crossmodel2 =
    \'ml6team/cross-encoder-mmarco-german-distilbert-base\' -- название
    модели искусственной нейронной сети на основе кросс-энкодера;

-   device -- устройство;

-   distilBERTmodel = \'distilbert-base-german-cased\' -- название BERT
    модели искусственной нейронной сети;

-   learning\_rate -- скорость обучения;

-   modeltype -- тип модели;

-   model\_bert -- загруженная модель BERT;

-   model\_cos -- загруженная модель искусственной нейронной сети с
    использованием косинусной меры;

-   model\_cross -- загруженная модель искусственной нейронной сети на
    основе кросс-энкодера;

-   model\_save\_path -- название папки для сохранения модели типа
    \'CosMeasure\', \'CrossEncoder\', \'CrossEncoder2\' ;

-   num\_epochs -- количество эпох для обучения;

-   train\_batch\_size -- размер пакета;

-   train\_dataloader -- данные для обучения.

-   test\_dataloader -- данные для тестирования

-   test\_shape -- количество данных для тестирования

-   text\_grade -- список текстов уровней грубости ошибки на немецком
    языке

-   text\_grade\_rus -- список текстов уровней грубости ошибки на
    русском языке

-   warmup\_steps -- количество начальных шагов при обучении

Методы класса:

-   get\_grade( x, score) -- получить значение уровня грубости ошибки;
    параметры: x -- значение из диапазона \[0, 1\], score -- границы для
    уровней грубости ошибки;

-   create\_model(device=\'cuda:0\', score=0) -- создать новую модель на
    основе одной из сторонних предобученных моделей Cosmodel или
    Crossmodel, или Crossmodel2, или distilBERTmodel, или BERTmodel;
    параметры: device -- устройство, score -- границы для уровней
    грубости ошибки;

-   load\_data(file, testpart=0.1, train\_batch\_size=16) -- загрузить
    данные из файла; параметры: file -- имя csv файла, содержащего
    данные для обучения и тестирования, в файле должны быть три столбца
    с именами «sent» - для предложения с ошибкой, «sentcorrect» - для
    предложения без ошибки, «level» -- для уровня грубости ошибки;
    testpart -- размер тестовой выборки относительно всех данных,
    принимает значение от 0 до 1; train\_batch\_size -- размер пакета;

-   fit(num\_epochs = 2, learning\_rate = 2e-4) -- обучить модель на
    обучающих данных; параметры: num\_epochs -- количество эпох
    обучения, learning\_rate -- скорость обучения;

-   predict(data) -- получить степень грубости ошибки по модели;
    параметры: data -- список из двух равновеликих списков: список
    предложений с ошибкой, список предложений без ошибок;

-   get\_accuracy(data) -- получить значение метрики accuracy;
    параметры: data -- список из трех равновеликих списков: предложения
    с ошибкой, предложения без ошибок, уровни грубости;

-   get\_accuracy\_m(data) -- получить значение метрики accuracy и
    матрицу; параметры: data -- список из трех равновеликих списков:
    предложения с ошибкой, предложения без ошибок, уровни грубости;

-   save\_model() -- сохранить обученную модель;

-   load\_model(pathname=\'grossmodel\') -- загрузить ранее обученную
    модель; параметры: pathname -- путь к файлам модели.

Описание класса MarkModel
=========================

Class MarkModel(listlayers=None, modelpath=None)

Параметры:

-   listlayers -- список количества нейронов в каждом скрытом слое +
    последний слой должен содержать 1 нейрон для получения оценки;

-   modelpath -- папка, где находятся файлы предобученной модели.

Поля класса:

-   batch\_size -- размер пакета;

-   epochs -- количество эпох для обучения;

-   learning\_rate -- скорость обучения;

-   listlayers -- структура слоев -- количество нейронов в каждом слое;

-   model -- модель;

-   X -- данные для обучения;

-   y -- данные для обучения.

Методы класса:

-   create\_model(modelpath) -- создать новую модель для обучения;
    параметры: modelpath -- папка, где находятся файлы предобученной
    модели;

-   load\_data(file\_csv) -- загрузить данные для обучения; параметры:
    file\_csv - имя csv файла, содержащего данные для обучения и
    тестирования, в файле должны быть следующие столбцы «numtoken»,
    «gram», «leks», «punkt», «orpho», «diskurs», «skips», «extra», «g1»,
    «g2», «g3»;

-   fit(batch\_size=32, num\_epochs=60, learning\_rate=1e-4, val=0) --
    обучить модель; параметры: batch\_size -- размер пакета, num\_epochs
    -- количество эпох для обучения, learning\_rate -- скорость
    обучения, val -- доля выборки для валидации;

-   predict(data) -- получить оценку за текст; параметры: data -- список
    описаний текстов, каждый текст представлен списком в формате:
    «gram», «leks», «punkt», «orpho», «diskurs», «skips», «extra», «g1»,
    «g2», «g3», «numtoken»;

-   val(dataX, dataY) -- получить значение метрики - Сумма разностей
    оценок; параметры: dataX - список списков в формате «gram», «leks»,
    «punkt», «orpho», «diskurs», «skips», «extra», «g1», «g2», «g3»,
    «numtoken», dataY - список оценок; метод формирует столбчатую
    диаграмму для количества текстов с различиями в оцнках на 1 балл, 2
    балла -- 12 баллов;

-   save\_model(path) -- сохранить модель; параметры: path -- путь;

-   load\_model(path) -- загрузить готовую модель из файла; параметры:
    path -- путь.

Модуль построения оценок включает следующие функции:

GetDataForGrossModel(user, password, host, database) -- функция
формирования на основе базы данных корпуса массива исходных данных для
обучения искусственной нейронной сети для определения грубости ошибки.
Параметры: user -- имя пользователя базы данных, password -- пароль
пользователя базы данных, host -- адрес базы данных, database -- имя
базы данных. Возвращает список кортежей в формате «предложение с
ошибкой», «предложение без ошибки», «уровень грубости ошибки».

GrossModelDataTo\_scv(file, user, password, host, database) -- функция
формирования на основе базы данных корпуса массива исходных данных для
обучения искусственной нейронной сети для определения грубости ошибки.
Параметры: user -- имя пользователя базы данных, password -- пароль
пользователя базы данных, host -- адрес базы данных, database -- имя
базы данных. Возвращает csv-файл со структурой «sent» -- предложение с
ошибкой, «sentcorrect» -- предложение без ошибки, «level» -- уровень
грубости ошибки.

GetDataForMarkModel(user, password, host, database) -- функция
формирования на основе базы данных корпуса массива исходных данных для
обучения искусственной нейронной сети для формирования оценки текста.
Параметры: user -- имя пользователя базы данных, password -- пароль
пользователя базы данных, host -- адрес базы данных, database -- имя
базы данных. Возвращает объект класса pandas.DataFrame в формате «idT» -
идентификатор текста, «text\_mark» - оценка текста, «gram» - количество
грамматических ошибок в тексте, «leks» - количество лексических ошибок в
тексте, «punkt» количество пунктуационных ошибок в тексте, «orpho» -
количество орфографических ошибок в тексте, «diskurs» - количество
дискурсивных ошибок в тексте, «skips» - количество ошибок, связанных с
пропусками слов в тексте, «extra» - количество ошибок, связанных с
присутствием лишних слов в тексте, «gram1» -- количество ошибок в
разделе «Грамматика», «gram2» -- количество ошибок в разделе
«Существительное», «gram3» -- Количество ошибок в разделе «Артикль»,
«gram4» -- Количество ошибок в разделе «Числительное», «gram5» --
Количество ошибок в разделе «Местоимение», «gram6» -- Количество ошибок
в разделе «Глагол», «gram7» -- Количество ошибок в разделе «Причастие»,
«gram8» -- Количество ошибок в разделе «Предлоги», «gram9» -- Количество
ошибок в разделе «Союзы», «gram10» -- Количество ошибок в разделе
«Прилагательное», «gram11» -- Количество ошибок в разделе «Наречия»,
«gram12» -- Количество ошибок в разделе «Порядок слов», «gram13» --
Количество ошибок в разделе «Сравнительные конструкции», «gram14» --
Количество ошибок в разделе «Инфинитивные конструкции», «leks15» --
Количество ошибок в разделе «Лексика», «leks16» -- Количество ошибок в
разделе «Выбор лексемы», «leks17» -- Количество ошибок в разделе
«Устойчивые обороты», «leks18» -- Количество ошибок в разделе
«Словообразование», «diskurs19» -- Количество ошибок в разделе
«Дискурс», «diskurs20» -- Количество ошибок в разделе «Логика»,
«diskurs21» -- Количество ошибок в разделе «Референтные связи внутри
текста», «diskurs22» -- Количество ошибок в разделе «Стиль», «g1» --
количество ошибок с уровнем грубости 1, «g2» -- количество ошибок с
уровнем грубости 2, «g3» -- количество ошибок с уровнем грубости 3,
«numsent» -- количество предложений в тексте, «numtoken» -- количество
слов в тексте, «numchar» -- количество символов в тексте.

MarkModelDataTo\_scv(file, user, password, host, database) -- функция
формирования массива исходных данных на основе базы данных корпуса для
обучения искусственной нейронной сети для формирования оценки текста.
Параметры: file -- имя файла, в который будут записаны данные, user --
имя пользователя базы данных, password -- пароль пользователя базы
данных, host -- адрес базы данных, database -- имя базы данных.

GetGrossError(textError, textCorrect) -- функция для определения
грубости ошибки. Параметры: textError -- предложение с ошибкой,
textCorrect -- предложение с исправленной ошибкой. Возвращает кортеж,
включающий текстовые формулировки грубости ошибки на немецком и русском
языке, так же значение, возвращенное нейронной сетью, если в качестве
модели были использованы сеть с косинусной мерой или кроссэнкодер.

GetTextMark(Val, model=None) -- функция для формирования оценки текста.
Параметры: Val -- список списков со статистикой ошибок в тексте в
формате \[\[\<список статистики ошибок для первого текста\>\],...\] ,
model -- объект с моделью, по которой необходимо вычислить оценку.
Возвращает список оценок или -1, если не указана модель.

Сценарии работы с библиотекой
=============================
Перед первым запуском необходимо установить все необходимые библиотеки для _Python_:

        pip install -r requirements.txt

Работа с моделью определения грубости ошибки
============================================

1.  Обучение новой модели для выбранного подхода и имеющегося набора
    обучающих данных

> Алгоритм:
>
> Загрузка данных, например, из csv-файла в структуру pandas.DataFrame,
> и преобразование их в три списка.
>
> Создание объекта класса GrossModel.
>
> Вызов метода для загрузки трех списков для обучения.
>
> Вызов метода для обучения.

import time

import matplotlib.pyplot as plt

import pandas as pd

\# файл с данными для обучения

fileName = \'data.csv\'

df = pd.read\_csv(fileName, sep = \';\')

\# создание модели

myModel = GrossModel(modelType = \'CrossEncoder2\', score=\[0.98, 0.93,
0.87\])

myModel.load\_data(fileName)

\# Количество данных для тестирования

num = myModel.test\_shape

train\_sent = \[df\[:-num\]\[\'sent\'\].to\_list()

train\_correct = df\[:-num\]\[\'sentcorrect\'\].to\_list()

train\_level = df\[:-num\]\[\'level\'\].to\_list()\]

test\_sent = \[df\[-num:\]\[\'sent\'\].to\_list()

test\_correct = df\[-num:\]\[\'sentcorrect\'\].to\_list()

test\_level = df\[-num:\]\[\'level\'\].to\_list()\]

ep = 40   \#\# Количество эпох

lr = 2e-5   \#\# learning\_rate

start\_time = time.time() \#\# точка отсчета времени

result = \[\] \#\# результаты обучения для каждой эпохи

y\_test = \[\] \#\# результаты на обучающей выборке для каждой эпохи

y\_train = \[\] \#\# результаты на тестовой выборке для каждой эпохи

\# расчет метрик до обучения

r\_matrix\_train, r\_train =
myModel.get\_accuracy\_m(train\_sent,train\_correct,train\_level)

r\_matrix\_test, r\_test =
myModel.get\_accuracy\_m(test\_sent,test\_correct,test\_level)

print(\'Эпоха 0\')

print(\'Тестовая: \' + str(round(r\_test,4)) + \';  Обучающая: \' +
str(round(r\_train,4)))

print(r\_matrix\_test)

result.append((0,r\_test,r\_train))

y\_test.append(r\_test)

y\_train.append(r\_train)

\# Цикл обучения

for i in range(ep):

  print(\'Эпоха \' + str(i+1))

  myModel.fit(num\_epochs = 1, learning\_rate = lr)

\# расчет метрик после обучения на одной эпохе

  r\_matrix\_train, r\_train =
myModel.get\_accuracy\_m(train\_sent,train\_correct,train\_level)

r\_matrix\_test, r\_test =
myModel.get\_accuracy\_m(test\_sent,test\_correct,test\_level)

print(\'Тестовая: \' + str(round(r\_test,4)) + \';  Обучающая: \' +
str(round(r\_train,4)))

print(r\_matrix\_test)

result.append((0,r\_test,r\_train))

y\_test.append(r\_test)

y\_train.append(r\_train)

end\_time = time.time() - start\_time

print(\'\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\--\')

print(\'Время: \' + str(int(end\_time) // 60) + \' минут \' +
str(int(end\_time) % 60) + \' секунд\')

print(\'Точность обучения: \' + str(round(max(y\_train),4)))

\# вывод графика обучения

t\_epoch = range(ep+1)

plt.plot(t\_epoch, y\_test, t\_epoch, y\_train)

plt.legend(\[\'test\',\'train\'\])

plt.show()

2.  Получение уровней грубости ошибок для обученной модели и оценка
    точности.

> Начальные условия: Объект GrossModel уже создан и, возможно, проведено
> обучение.
> Можно использовать готовую обученную модель скачав и распаковав архив с сайта https://pact.ai.petrsu.ru/models/
>
> Алгоритм:
>
> Загрузка данных для тестирования, например, из csv-файла в структуру
> pandas.DataFrame, и преобразование их в три списка.
>
> Вызов метода для получения уровней грубости.
>
> Вызов метода для получения значения метрики Accuracy
>
> Вызов метода для получения значения метрики Accuracy и матрицы.

myModel = GrossModel(modelType = \'CrossEncoder2\')

myModel.load\_model(pathname=\'mymodel\')

dftest = pd.read\_csv(\'Test.csv\')

r\_matrix\_train, r\_train =
myModel.get\_accuracy\_m(\[dftest\[\'sent\'\].to\_list(),dftest\[\'sentcorrect\'\].to\_list(),dftest\[\'level\'\].to\_list()\])

print(str(round(r\_train,4)))

print(r\_matrix\_train)

3.  Использование предобученной модели кроссэнкодера для получения
    уровней грубости ошибок

> Алгоритм:
>
> Вызов функции GetGrossError()

GetGrossError(\'Jetzt muss man sich auf Abende und die Wochenenden
undkonzentrieren.\', \'Jetzt muss man sich auf Abende und die
Wochenenden konzentrieren.\')

Работа с моделью выставления оценки за текст
============================================

1.  Обучение новой модели на имеющемся наборе обучающих данных

> Алгоритм:
>
> Создание объекта класса MarkModel с параметром, описывающим количество
> нейронов в каждом скрытом слое.
>
> Вызов метода для загрузки данных из csv-файла.
>
> Вызов метода для обучения.
>
> Вызов метода для расчета суммы разностей между реальными оценками и
> построенными оценками

myModel = MarkModel(listlayers = \[20,11,5,1\])

myModel.load\_data(\'data.csv\')

myModel.fit(num\_epochs = 30)

print(myModel.val(\[\[1,1,0,0,0,0,0,1,1,0,512\],\[1,3,0,3,0,0,0,2,5,0,752\]\],
\[10,5\]))

2.  Использование предобученной модели для получения оценки

> Можно использовать готовую обученную модель скачав и распаковав архив с сайта https://pact.ai.petrsu.ru/models/
>
> Алгоритм:
>
> Создание объекта класса MarkModel с параметром, описывающим место
> расположения файлов модели;
>
> Вызов функции GetTextMark ().

myModel = MarkModel(modelpath = 'model\_mark')

print(GetTextMark(\[\[1,1,0,0,0,0,0,1,1,0,512\],\[1,3,0,3,0,0,0,2,5,0,752\]\],myModel))
